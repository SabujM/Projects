{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in ./.local/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests) (2.9)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/site-packages (from html5lib) (1.14.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/site-packages (from html5lib) (0.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/1/archivelist/year-2016,month-12,starttime-42705.cms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlcontent1=page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(htmlcontent1,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in spans:\n",
    "    a=i.find_all(\"a\")\n",
    "    for j in a:\n",
    "        urls.append(j.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "author=[]\n",
    "heading=[]\n",
    "content=[]\n",
    "verticle=[]\n",
    "for link in urls:\n",
    "    try: \n",
    "        page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "        htmlcontent=page.content\n",
    "        soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "        try:\n",
    "            try:\n",
    "                divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                for i in divs:\n",
    "                    divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                    for j in divs1:\n",
    "                        head=j.find_all(\"h1\")\n",
    "                        heading.append(head[0].text)\n",
    "                    try:\n",
    "                        dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                        date.append(dat[0].text[9:])\n",
    "                    except:\n",
    "                        date.append(\"NA\")\n",
    "                    try:\n",
    "                        aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                        author.append(aut[0].text)\n",
    "                    except:\n",
    "                        author.append(\"NA\")\n",
    "            except:\n",
    "                heading.append(\"NA\")\n",
    "                date.append(\"NA\")\n",
    "                author.append(\"NA\")\n",
    "            for i in divs:\n",
    "                con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                content.append(con[0].text)\n",
    "                try:\n",
    "                    vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                    verticle.append(vert[1].text)\n",
    "                except:\n",
    "                    verticle.append(\"NA\")\n",
    "        except:\n",
    "            pass       \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42706.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 58, 58, 58, 58)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date), len(author), len(heading), len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42707.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42708.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42709.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42710.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42711.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 152, 152, 152, 152)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42712.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 168, 168, 168, 168)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42713.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 187, 187, 187, 187)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42714.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 202, 202, 202, 202)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42715.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 221, 221, 221, 221)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42716.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 235, 235, 235, 235)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42717.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 259, 259, 259, 259)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date),len(author), len(heading),len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42718.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42719.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42720.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42721.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42722.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42723.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42724.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42725.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42726.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42727.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42728.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42729.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42730.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42731.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42732.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42733.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42734.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42734.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    page=requests.get(\"https://timesofindia.indiatimes.com/2016/12/2/archivelist/year-2016,month-12,starttime-42735.cms\")\n",
    "    htmlcontent1=page.content\n",
    "    soup=BeautifulSoup(htmlcontent1,\"html.parser\")\n",
    "    spans=soup.find_all(\"span\", {\"style\":\"font-family:arial ;font-size:12;color: #006699\"})\n",
    "    urls=[]\n",
    "    for i in spans:\n",
    "        a=i.find_all(\"a\")\n",
    "        for j in a:\n",
    "            urls.append(j.get(\"href\"))\n",
    "    for link in urls:\n",
    "        try: \n",
    "            page=requests.get(\"https://timesofindia.indiatimes.com/\"+link)\n",
    "            htmlcontent=page.content\n",
    "            soup=BeautifulSoup(htmlcontent,\"html.parser\") \n",
    "            try:\n",
    "                try:\n",
    "                    divs=soup.find_all(\"div\", class_=\"videos_player_md main_dpygrid\")\n",
    "                    for i in divs:\n",
    "                        divs1=i.find_all(\"div\", class_=\"as_heading\")\n",
    "                        for j in divs1:\n",
    "                            head=j.find_all(\"h1\")\n",
    "                            heading.append(head[0].text)\n",
    "                        try:\n",
    "                            dat=i.find_all(\"div\", {\"data-plugin\":\"dateformat\"})\n",
    "                            date.append(dat[0].text[9:])\n",
    "                        except:\n",
    "                            date.append(\"NA\")\n",
    "                        try:\n",
    "                            aut=i.find_all(\"a\", class_=\"auth_detail\")\n",
    "                            author.append(aut[0].text)\n",
    "                        except:\n",
    "                            author.append(\"NA\")\n",
    "                except:\n",
    "                    heading.append(\"NA\")\n",
    "                    date.append(\"NA\")\n",
    "                    author.append(\"NA\")\n",
    "                for i in divs:\n",
    "                    con=i.find_all(\"div\", class_=\"Normal\")\n",
    "                    content.append(con[0].text)\n",
    "                    try:\n",
    "                        vert=soup.find_all(\"span\", {\"itemprop\":\"name\"})\n",
    "                        verticle.append(vert[1].text)\n",
    "                    except:\n",
    "                        verticle.append(\"NA\")\n",
    "            except:\n",
    "                pass       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 523, 523, 523, 523)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heading),len(date),len(author), len(content), len(verticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "news_dec=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dec[\"Date\"]=date\n",
    "news_dec[\"Author\"]=author\n",
    "news_dec[\"Verticle\"]=verticle\n",
    "news_dec[\"Heading\"]=heading\n",
    "news_dec[\"Description\"]=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in news_dec:\n",
    "    for j in news_dec.index:\n",
    "        news_dec.loc[j,i] = news_dec.loc[j,i].encode('UTF-8','ignore').decode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dec.to_csv(\"News_Classification_for_Feb.csv\", encoding=\"utf-32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
